[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.version]
path = "src/mtg_ai/__init__.py"

[project]
name = "mtg-ai"
description = "Magic the Gathering general information and combo llama-based LLM"
authors = [{name = "Thomas Meyer", email = "thomas@thomasmeyer.co" }]
requires-python = ">=3.11,<3.13"
dynamic = ["version"]

[project.scripts]
mtg-ai = "mtg_ai:_cli_main"
mtg-ai-webserver = "mtg_ai_webserver:run"
mtg-ai-rag-webserver = "mtg_ai_rag_webserver:run"

[tool.pixi.project]
channels = [ "nvidia", "pytorch", "xformers", "conda-forge", "anaconda"]
platforms = ["linux-64"]

[tool.pixi.tasks]
lint = "pre-commit run --all-files"
test = "pytest"
docker-build = { depends-on = ["docker-build-llm-training", "docker-build-rag-webserver", "docker-build-webserver"] }
docker-build-llm-training = "docker build --progress=plain -t mtg-ai --target llm-training ."
docker-build-rag-webserver = "docker build --progress=plain -t mtg-ai-rag-webserver --target mtg_ai_rag_webserver ."
docker-build-webserver = "docker build --progress=plain -t mtg-ai-webserver --target mtg_ai_webserver ."
docker-run = "docker run --gpus all -p 8888:8888 -p 8889:8889 mtg-ai:latest"
tensorboard = "tensorboard --logdir=./logs --port=8889 --bind_all"
mtg_ai_webserver = "python src/mtg_ai_webserver/run.py"
mtg_ai_rag_webserver = "hypercorn --config ./hypercorn_config.toml mtg_ai_rag_webserver:app"

[tool.pixi.feature.dev.tasks]
jupyter-lab = "jupyter-lab --ip=0.0.0.0 --port=8889 --no-browser"

[tool.pixi.environments]
default = { solve-group = "default" }
test = { features = ["test"], solve-group = "default" }
dev = { features = ["dev", "test"], solve-group = "default" }

[tool.pixi.pypi-options]
no-build-isolation = ["flash-attn"]

[tool.pixi.dependencies]
cuda-toolkit = "=12.3"
haystack-ai = "~=2.7.0"

[tool.pixi.pypi-dependencies]
mtg-ai = { path = ".", editable = true }
unsloth = "~=2024.12.4"
unsloth_zoo = { git = "https://github.com/unslothai/unsloth-zoo.git" }
torch = "~=2.5.1"
tensorboard = "~=2.18.0"
torch-tb-profiler = "~=0.4.3"
transformers = "~=4.46.3"
datasets = "~=3.1.0"
accelerate = "~=1.1.1"
evaluate = "~=0.4.3"
bitsandbytes = "~=0.44.1"
huggingface_hub = "~=0.26.2"
trl = "~=0.12.1"
peft = "~=0.13.2"
sentence-transformers = "~=3.3.1"
rapidfuzz = "~=3.3.1"
rich = ">=13.9.4"
flash-attn = { url = "https://github.com/Dao-AILab/flash-attention/releases/download/v2.7.0.post2/flash_attn-2.7.0.post2+cu12torch2.5cxx11abiFALSE-cp312-cp312-linux_x86_64.whl" }
fastapi = "~=0.115.6"
hypercorn = { version = ">=0.17.3,<0.18", extras = ["trio"]}
pydantic-settings = ">=2.7.0,<3"
trio = ">=0.28.0,<0.29"

[tool.pixi.feature.dev.pypi-dependencies]
colorlog = "~=6.9.0"
ipykernel = "~=6.29.5"
jupyter = ">=1.1.1"
rpds-py = "~=0.21.0"
ruff  = "~=0.8.0"
jupyterlab = "~=4.2.6"
ipython = "~=8.29.0"
pixi-kernel = "~=0.5.1"
ipywidgets = "~=8.1.5"

[tool.pixi.feature.test.pypi-dependencies]
pytest = "~=8.3.3"


# Extra tool configs

[tool.ruff]
line-length = 88
target-version = "py311"
fix = true
exclude = [
    ".git",
    ".hg",
    ".mypy_cache",
    ".tox",
    ".venv",
    "_build",
    "build",
    "dist",
    "*.ipynb",
]

[tool.ruff.lint]
select = ["E", "F", "B", "I"]
fixable = ["E", "F", "B", "I"]
ignore = ["E501"]

[tool.ruff.format]
docstring-code-format = true
docstring-code-line-length = 20

