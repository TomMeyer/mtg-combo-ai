# MTG AI Training parameters
model_id: "unsloth/Meta-Llama-3.1-8B-Instruct" # Hugging Face model id
datasets:                                 # path to datasets or Huggingface Dataset names
  - FringeFields/MTG-Rules-QA
  - FringeFields/MTG-Cards-QA
  - FringeFields/MTG-EDH-Combos-QA
max_seq_length:  1024                     # max sequence length for model and packing of the dataset
enable_profiling: true                   # enable profiling
# training parameters
output_dir: "./training_results/"         # Overriden by training script
report_to: "tensorboard"                  # report metrics to tensorboard
learning_rate: 0.0002                     # learning rate 2e-4
lr_scheduler_type: "cosine"               # learning rate scheduler
num_train_epochs: 1                       # number of training epochs
dataset_num_proc: 4                      # number of processes to use for data loading
dataloader_num_workers: 0                 # number of workers to use for data loading
per_device_train_batch_size: 24           # batch size per device during training
per_device_eval_batch_size: 8             # batch size for evaluation
gradient_accumulation_steps: 1            # number of steps before performing a backward/update pass
optim: adamw_torch_fused                        # use torch adamw optimizer
logging_steps: 50                         # log every 10 steps
save_strategy: steps                      # save checkpoint every epoch
eval_strategy: epoch                      # evaluate every epoch
max_grad_norm: 0.3                        # max gradient norm
warmup_ratio: 0.03                        # warmup ratio
bf16: true                                # use bfloat16 precision
tf32: true                                # use tf32 precision
packing: true
save_steps: 0.1
